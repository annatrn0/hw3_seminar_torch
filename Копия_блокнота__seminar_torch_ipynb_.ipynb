{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Копия блокнота \"seminar_torch.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d805a85564642fba7e3e3f492a019f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37d3acf37e53465fb625932e4aa43f8d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51cfd4a5244946308f2a45e6f20178c3",
              "IPY_MODEL_7c8416e3ec8f418e8246e9d17b156402"
            ]
          }
        },
        "37d3acf37e53465fb625932e4aa43f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51cfd4a5244946308f2a45e6f20178c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cae3c1972330484092630efd1778f90b",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 12238,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 161,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5c9ad620ff64837bb6253486d2b37dd"
          }
        },
        "7c8416e3ec8f418e8246e9d17b156402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9c2693964c64a939f73e57cc5bf8c27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 161/12238 [00:20&lt;11:31, 17.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f8db67df77d401682d17506d6b0f09c"
          }
        },
        "cae3c1972330484092630efd1778f90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5c9ad620ff64837bb6253486d2b37dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9c2693964c64a939f73e57cc5bf8c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f8db67df77d401682d17506d6b0f09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t75zdooZe8j"
      },
      "source": [
        "# Large scale text analysis with deep learning (3 points)\n",
        "\n",
        "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
        "\n",
        "_Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15oL2HOSDRFC",
        "outputId": "c636badd-cbc8-40d2-fdb8-574a8ac5cef4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWS0E8OHZe8s"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbjrfFspZe8s"
      },
      "source": [
        "### About the challenge\n",
        "For starters, let's download and unpack the data from [here]. \n",
        "\n",
        "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsBw4DmiZe8t",
        "outputId": "3d44c0b7-9647-4046-9da7-3ef7d223e53c"
      },
      "source": [
        "# !wget https://ysda-seminars.s3.eu-central-1.amazonaws.com/Train_rev1.zip\n",
        "# !unzip Train_rev1.zip\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Train_rev1.csv\", index_col=None)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(244768, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "NaYFLUUsZe8u",
        "outputId": "d5d718b5-a056-482b-fe24-2de84474823c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12612628</td>\n",
              "      <td>Engineering Systems Analyst</td>\n",
              "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
              "      <td>Dorking, Surrey, Surrey</td>\n",
              "      <td>Dorking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12612830</td>\n",
              "      <td>Stress Engineer Glasgow</td>\n",
              "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
              "      <td>Glasgow, Scotland, Scotland</td>\n",
              "      <td>Glasgow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 35000/annum 25-35K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12612844</td>\n",
              "      <td>Modelling and simulation analyst</td>\n",
              "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
              "      <td>Hampshire, South East, South East</td>\n",
              "      <td>Hampshire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 40000/annum 20-40K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12613049</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
              "      <td>27500</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12613647</td>\n",
              "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
              "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Id  ...        SourceName\n",
              "0  12612628  ...  cv-library.co.uk\n",
              "1  12612830  ...  cv-library.co.uk\n",
              "2  12612844  ...  cv-library.co.uk\n",
              "3  12613049  ...  cv-library.co.uk\n",
              "4  12613647  ...  cv-library.co.uk\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzN578PlZe8v"
      },
      "source": [
        "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
        "\n",
        "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
        "\n",
        "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7m4_nPD5Ze8v",
        "outputId": "cf2d3276-92e0-4b10-d4c4-cb6d3c81d129"
      },
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data['Log1pSalary'], bins=20);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ4sxIXDZe8w"
      },
      "source": [
        "Our task is to predict one number, __Log1pSalary__.\n",
        "\n",
        "To do so, our model can access a number of features:\n",
        "* Free text: __`Title`__ and  __`FullDescription`__\n",
        "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "6dYdc8PIZe8w",
        "outputId": "6b123587-3ecd-4084-8e33-f68094afade1"
      },
      "source": [
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "TARGET_COLUMN = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "data[text_columns] = data[text_columns].fillna('NaN')\n",
        "\n",
        "data.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55549</th>\n",
              "      <td>68679896</td>\n",
              "      <td>Telesales Recruitment Advisor</td>\n",
              "      <td>Summary of role To work as part of a Recruitme...</td>\n",
              "      <td>Cheadle, Cheshire Cheshire North West</td>\n",
              "      <td>UK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Knowledge Web</td>\n",
              "      <td>Other/General Jobs</td>\n",
              "      <td>From 15,000 to 25,000 per annum Salary 15K bas...</td>\n",
              "      <td>20000</td>\n",
              "      <td>totaljobs.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244255</th>\n",
              "      <td>72695353</td>\n",
              "      <td>Junior Embedded Linux Engineer  Near Guildford...</td>\n",
              "      <td>Computer Futures are seeking a number of Embed...</td>\n",
              "      <td>Guildford Surrey England</td>\n",
              "      <td>Guildford</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Computer Futures</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 -37000 per annum</td>\n",
              "      <td>31000</td>\n",
              "      <td>gojobsearch.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219273</th>\n",
              "      <td>72340244</td>\n",
              "      <td>Physiotherapist</td>\n",
              "      <td>Job Title: Physiotherapist Job Type: Full time...</td>\n",
              "      <td>Cambridge, Cambridgeshire</td>\n",
              "      <td>Cambridge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Jane Lewis Health Social Care</td>\n",
              "      <td>Healthcare &amp; Nursing Jobs</td>\n",
              "      <td>26000 - 32000/annum 26000 - 32000</td>\n",
              "      <td>29000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Id  ...         SourceName\n",
              "55549   68679896  ...      totaljobs.com\n",
              "244255  72695353  ...  gojobsearch.co.uk\n",
              "219273  72340244  ...   cv-library.co.uk\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJGyz6vgZe8w"
      },
      "source": [
        "### Preprocessing text data\n",
        "\n",
        "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
        "\n",
        "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
        "\n",
        "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djOwAHFHZe8w",
        "outputId": "c10e47fd-b874-47e1-85b4-5d65791afe64"
      },
      "source": [
        "print(\"Raw text:\")\n",
        "print(data[\"FullDescription\"][2::100000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw text:\n",
            "2         Mathematical Modeller / Simulation Analyst / O...\n",
            "100002    A successful and high achieving specialist sch...\n",
            "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNGh27ebZe8x"
      },
      "source": [
        "import nltk\n",
        "#TODO YOUR CODE HERE\n",
        "data['Title'] = data['Title'].str.lower()\n",
        "data['FullDescription'] = data['FullDescription'].str.lower()\n",
        "\n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "data['Title'] = data['Title'].map(lambda x: \" \".join(tokenizer.tokenize(x)))\n",
        "data['FullDescription'] = data['FullDescription'].map(lambda x: \" \".join(tokenizer.tokenize(x)))\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSSSLCO1Ze8x"
      },
      "source": [
        "Now we can assume that our text is a space-separated list of tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWpQuVt7Ze8x",
        "outputId": "5eed0d4f-4c9f-4517-bad4-d219e01e7734"
      },
      "source": [
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OeLTODAZe8x"
      },
      "source": [
        "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
        "\n",
        "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVN-jztCZe8x"
      },
      "source": [
        "from collections import Counter\n",
        "both = pd.concat([data['Title'], data['FullDescription']])\n",
        "both = both.map(lambda x: tokenizer.tokenize(x))\n",
        "token_counts = Counter()\n",
        "for string in both:\n",
        "  token_counts.update(string)\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "#TODO <YOUR CODE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kg5VqyhNSVa",
        "outputId": "225a5cd0-40ba-4799-f56a-84a8a2dec32e"
      },
      "source": [
        "token_counts['systems']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77071"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-40HetcZe8y",
        "outputId": "fac410b2-f3ec-4867-a75e-778d4af77c36"
      },
      "source": [
        "  print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique tokens : 202704\n",
            "('and', 2657388)\n",
            "('.', 2523216)\n",
            "(',', 2318606)\n",
            "('the', 2080994)\n",
            "('to', 2019884)\n",
            "...\n",
            "('stephanietraveltraderecruitmnt', 1)\n",
            "('ruabon', 1)\n",
            "('lowehays', 1)\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNCP31cKZe8y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "482600c7-4a3d-4429-c2a9-6d216813f6a5"
      },
      "source": [
        "# Let's see how many words are there for each count\n",
        "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
        "plt.xlabel(\"Word counts\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIWo0dm5Ze8y"
      },
      "source": [
        "__Task 1.1__ Get a list of all tokens that occur at least 10 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUB3KExsZe8y"
      },
      "source": [
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "#TODO <YOUR CODE>\n",
        "tokens = sorted(t for t, c in token_counts.items() if c >= min_count)\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqDMQVGyZe8y",
        "outputId": "4685b690-9dba-4b82-bed9-4ccd64131d47"
      },
      "source": [
        "print(\"Vocabulary size:\", len(tokens))\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 34158\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8JGwF9VZe8z"
      },
      "source": [
        "__Task 1.2__ Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcrdkC_RZe8z"
      },
      "source": [
        "# TODO <YOUR CODE>\r\n",
        "token_to_id = {t: i for i, t in enumerate(tokens)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrfWfH7MZe8z",
        "outputId": "394df063-0195-40ab-ba79-bfd76da82970"
      },
      "source": [
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYj9cyTXZe8z"
      },
      "source": [
        "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExQNSGMrZe8z"
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bd1OxoyZe80",
        "outputId": "9da84c68-2ad1-4fc8-8f99-a0611e4040ca"
      },
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10807 30161  2166     1     1]\n",
            " [15020  2844     1     1     1]\n",
            " [27645 10201    16 15215 10804]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsXCKzrUZe80"
      },
      "source": [
        "Now let's  encode the categirical data we have.\n",
        "\n",
        "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr-qdrh3Ze81",
        "outputId": "fba2ed3f-4c2c-4efa-e124-09c1bb87da78"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
              "               sparse=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRZSgQdhNEs7",
        "outputId": "92618929-c7ad-4ab4-9d1d-95548192c178"
      },
      "source": [
        "data[categorical_columns].head().to_dict(orient='list')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Category': ['Engineering Jobs',\n",
              "  'Engineering Jobs',\n",
              "  'Engineering Jobs',\n",
              "  'Engineering Jobs',\n",
              "  'Engineering Jobs'],\n",
              " 'Company': ['Gregory Martin International',\n",
              "  'Gregory Martin International',\n",
              "  'Gregory Martin International',\n",
              "  'Gregory Martin International',\n",
              "  'Gregory Martin International'],\n",
              " 'ContractTime': ['permanent',\n",
              "  'permanent',\n",
              "  'permanent',\n",
              "  'permanent',\n",
              "  'permanent'],\n",
              " 'ContractType': ['NaN', 'NaN', 'NaN', 'NaN', 'NaN'],\n",
              " 'LocationNormalized': ['Dorking', 'Glasgow', 'Hampshire', 'Surrey', 'Surrey']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJDgbkHZZe81"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sURw9HXZe81",
        "outputId": "ea50adef-b8f9-4fa8-9c2c-f84685c672fc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size =  195814\n",
            "Validation size =  48954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8wpyN1Ze81"
      },
      "source": [
        "import torch\n",
        "\n",
        "def to_tensors(batch, device):\n",
        "    batch_tensors = dict()\n",
        "    for key, arr in batch.items():\n",
        "        if key in [\"FullDescription\", \"Title\"]:\n",
        "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
        "        else:\n",
        "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
        "    return batch_tensors\n",
        "\n",
        "def make_batch(data, max_len=None, word_dropout=0, device=torch.device('cpu')):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if TARGET_COLUMN in data.columns:\n",
        "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
        "    \n",
        "    return to_tensors(batch, device)\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRKoBF_gZe82",
        "outputId": "2b6b0b95-0c32-4241-ade6-43252de46599"
      },
      "source": [
        "make_batch(data_train[:3], max_len=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Categorical': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " 'FullDescription': tensor([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451, 32939],\n",
              "         [29239,   197, 19175, 20042, 15554, 23162,  4051, 25511,   907,    82],\n",
              "         [30746, 21956, 20601,  6409, 16451,  8165, 27493,   982, 30412, 17746]]),\n",
              " 'Title': tensor([[27645, 29893, 33674,     1,     1,     1,     1],\n",
              "         [29239,   197, 19175, 20042, 15554, 23162,  4051],\n",
              "         [10609, 30412, 17746,    33,  8705, 29157,    65]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8f9-Y01Ze82"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our basic model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "![scheme](https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-zT-Hu_Ze82"
      },
      "source": [
        "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obkMJ46pZe83"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA6qpXssWjUt",
        "outputId": "674ce1f5-3f89-4292-fc5a-20ee34cbc49b"
      },
      "source": [
        "temp = make_batch(data_train[:3], max_len=10)\r\n",
        "temp['Title'].shape, temp['FullDescription'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 7]), torch.Size([3, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4LgLJtEZe83",
        "outputId": "7de49d39-ddde-4cee-9738-ba2aec82add7"
      },
      "source": [
        "class SalaryPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
        "        super().__init__()\n",
        "        #  YOUR CODE HERE\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, batch):\n",
        "        # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8WvtlOUZe83"
      },
      "source": [
        "model = SalaryPredictor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBS7PlCrZe83"
      },
      "source": [
        "model = SalaryPredictor()\n",
        "batch = make_batch(data_train[:100])\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "dummy_pred = model(batch)\n",
        "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
        "assert dummy_pred.shape == torch.Size([100])\n",
        "assert len(np.unique(dummy_pred.detach().numpy())) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
        "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmImJv70Ze83"
      },
      "source": [
        "#### Training and evaluation\n",
        "\n",
        "As usual, we gonna feed our monster with random minibatches of data. \n",
        "\n",
        "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBwOV5duZe84"
      },
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, device=torch.device('cpu'), **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            yield batch\n",
        "        \n",
        "        if not cycle: break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7ExfuFkZe84"
      },
      "source": [
        "### Model training\n",
        "\n",
        "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNW1PL0mZe84"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "DEVICE = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsu0gequZe84"
      },
      "source": [
        "def print_metrics(model, data, batch_size=BATCH_SIZE, name=\"\", **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
        "            batch_pred = model(batch)\n",
        "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
        "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
        "            num_samples += len(batch_y)\n",
        "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
        "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % mse)\n",
        "    print(\"Mean absolute error: %.5f\" % mae)\n",
        "    return mse, mae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474,
          "referenced_widgets": [
            "0d805a85564642fba7e3e3f492a019f3",
            "37d3acf37e53465fb625932e4aa43f8d",
            "51cfd4a5244946308f2a45e6f20178c3",
            "7c8416e3ec8f418e8246e9d17b156402",
            "cae3c1972330484092630efd1778f90b",
            "b5c9ad620ff64837bb6253486d2b37dd",
            "e9c2693964c64a939f73e57cc5bf8c27",
            "1f8db67df77d401682d17506d6b0f09c"
          ]
        },
        "id": "guTdyDx1Ze84",
        "outputId": "6401a4b4-7ea2-4e29-e4b5-37c69c82de36"
      },
      "source": [
        "model = SalaryPredictor().to(DEVICE)\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    model.train()\n",
        "    for i, batch in tqdm.tqdm_notebook(enumerate(\n",
        "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=DEVICE)),\n",
        "            total=len(data_train) // BATCH_SIZE\n",
        "        ):\n",
        "        pred = model(batch)\n",
        "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print_metrics(model, data_val)\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d805a85564642fba7e3e3f492a019f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12238.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-190-d69df8d2c212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     for i, batch in tqdm.tqdm_notebook(enumerate(\n\u001b[1;32m      9\u001b[0m             iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=DEVICE)),\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         ):\n\u001b[1;32m     12\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-187-e4889b890af4>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(data, batch_size, shuffle, cycle, device, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-3872c07e9d52>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(data, max_len, word_dropout, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Categorical'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_dropout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m         \"\"\"\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3350\u001b[0m         new_data = self._mgr.take(\n\u001b[0;32m-> 3351\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3352\u001b[0m         )\n\u001b[1;32m   3353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"take\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m         return self.reindex_indexer(\n\u001b[0;32m-> 1457\u001b[0;31m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m         )\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m             \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             new_blocks = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[1;32m   1403\u001b[0m                     \u001b[0;31m#  we may try to only slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0mtaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m                     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0monly_slice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m                         \u001b[0mtaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_indices_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOTxPZ-HZe85"
      },
      "source": [
        "### Bonus part: explaining model predictions\n",
        "\n",
        "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
        "\n",
        "There are, however, some ways to look inside the black box:\n",
        "* Seeing how model responds to input perturbations\n",
        "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
        "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
        "\n",
        "Today we gonna try the first method just because it's the simplest one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiR3o34JZe85"
      },
      "source": [
        "def explain(model, sample, col_name='Title'):\n",
        "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
        "    sample = dict(sample)\n",
        "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
        "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
        "\n",
        "    for drop_i in range(len(sample_col_tokens)):\n",
        "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
        "                                                   for i, tok in enumerate(sample_col_tokens)) \n",
        "\n",
        "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
        "    diffs = baseline_pred - predictions_drop_one_token\n",
        "    return list(zip(sample_col_tokens, diffs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI33D3GTZe85"
      },
      "source": [
        "from IPython.display import HTML, display_html\n",
        "\n",
        "\n",
        "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
        "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
        "              font_style=\"font-size:14px;\"\n",
        "             ):\n",
        "    \n",
        "    def get_color_hex(weight):\n",
        "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
        "        return '#%02X%02X%02X' % rgba[:3]\n",
        "    \n",
        "    tokens_html = [\n",
        "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
        "        for token, weight in tokens_and_weights\n",
        "    ]\n",
        "    \n",
        "    \n",
        "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
        "    if display:\n",
        "        display_html(HTML(raw_html))\n",
        "        \n",
        "    return raw_html\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUMaLEe-Ze86"
      },
      "source": [
        "i = 36605\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRQWt07XZe86"
      },
      "source": [
        "i = 12077\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKjfyy6hZe86"
      },
      "source": [
        "i = np.random.randint(len(data))\n",
        "print(\"Index:\", i)\n",
        "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbbdF08aZe86"
      },
      "source": [
        "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
      ]
    }
  ]
}